# Question answering datasets

## Datasets included in NLIWOD

| Dataset                  |                   Paper                          |              Download Link                       |           Notes         |
|--------------------------|:------------------------------------------------:|:------------------------------------------------:|-------------------------|    
|DBpedia-Entity v2 INEX       |[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)| [Link](https://github.com/iai-group/DBpedia-Entity/tree/master/collection/v2)||
|DBpedia-Entity v2 QALD2      |[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|[Link](https://github.com/iai-group/DBpedia-Entity/tree/master/collection/v2) ||
|DBpedia-Entity v2 SemSearch  |[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|[Link](https://github.com/iai-group/DBpedia-Entity/tree/master/collection/v2) ||
|DBpedia-Entity v2 TREC Entity|[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|[Link](https://github.com/iai-group/DBpedia-Entity/tree/master/collection/v2) ||
|LC-QuAD 1                    |[Link](http://jens-lehmann.org/files/2017/iswc_lcquad.pdf)| [Link](https://figshare.com/articles/dataset/LC-QuAD_QALDformat/5818452)||
|LC-QuAD 2                    |[Link](http://jens-lehmann.org/files/2019/iswc_lcquad2.pdf)|Original: [Link](http://lc-quad.sda.tech/) <br> Including Answers (QALD): [Link](https://hobbitdata.informatik.uni-leipzig.de/lcquad2_qald/)||
|NLQ          	           |-| [Link](http://2015.okbqa.org/nlq)||
|QALD-1                    |[Link](http://qald.aksw.org/1/documents/qald-1-challenge.pdf)|[Link](https://github.com/ag-sc/QALD/tree/master/1) ||
|QALD-2                    |[Link](http://qald.aksw.org/2/documents/qald-2-challenge.pdf)|[Link](https://github.com/ag-sc/QALD/tree/master/2) ||
|QALD-3                    |[Link](https://www.researchgate.net/publication/278716415_Multilingual_Question_Answering_over_Linked_Data_QALD-3_Lab_Overview)|[Link](https://github.com/ag-sc/QALD/tree/master/3) ||
|QALD-4                    |[Link](https://www.researchgate.net/publication/278798193_Question_answering_over_linked_data_QALD-4)| [Link](https://github.com/ag-sc/QALD/tree/master/4) ||
|QALD-5                    |[Link](https://www.researchgate.net/publication/282124138_Question_Answering_over_Linked_Data_QALD-5)| [Link](https://github.com/ag-sc/QALD/tree/master/5) ||
|QALD-6                    |[Link](https://link.springer.com/chapter/10.1007/978-3-319-46565-4_13)| [Link](https://github.com/ag-sc/QALD/tree/master/6) ||
|QALD-7                    |[Link](https://svn.aksw.org/papers/2017/ESWC_2017_QALD/public.pdf)| [Link](https://github.com/ag-sc/QALD/tree/master/7) ||
|QALD-8                    |[Link](https://www.semanticscholar.org/paper/8th-Challenge-on-Question-Answering-over-Linked-Usbeck-Ngomo/44ddbf4032e70c4aabfa6799df5ee2b5ce51a468)| [Link](https://github.com/ag-sc/QALD/tree/master/8/data)||
|QALD-9                    |[Link](https://www.semanticscholar.org/paper/9th-Challenge-on-Question-Answering-over-Linked-Usbeck-Gusmita/4f83e1b64f57ae0d546076279426e85c0e60298b)| [Link](https://github.com/ag-sc/QALD/tree/master/9/data) ||
|SimpleQuestionsWikidata   |[Link](https://www.researchgate.net/publication/319482301_Question_Answering_Benchmarks_for_Wikidata)| [Link](https://github.com/askplatypus/wikidata-simplequestions)||
|SimpleQuestionsDBpedia   |[Link](https://aclanthology.org/C18-1178)| [Link](https://github.com/castorini/SimpleDBpediaQA)||
|WDAquaCore0Logs       |-| Original: [Link](https://github.com/WDAqua/WDAquaCore0Questions)  <br> Including Answers (QALD): [Link](https://github.com/dice-group/NLIWOD/blob/master/qa.datasets/src/main/resources/wdaqua-core0-logs_qald.json)| The repository contains two files, one with the dataset, the other one with raw questions without answers. Thus, we include only the former and add answers by querying the KB in Oct. 2020.|
|EventQA       |[Link](https://arxiv.org/abs/2004.11861)| [Link](https://github.com/dice-group/gerbil/issues/314)||
|RuBQ 1.0 |[Link](https://link.springer.com/chapter/10.1007/978-3-030-62466-8_7)| [Link](https://github.com/vladislavneon/RuBQ/tree/master/RuBQ_1.0)||
|RuBQ 2.0 |[Link](https://link.springer.com/chapter/10.1007/978-3-030-77385-4_32)| [Link](https://github.com/vladislavneon/RuBQ/tree/master/RuBQ_2.0)||

NOTE: PARL.AI does a tremendous job in including different tasks. Thus it would make sense to analyze their state before starting to include more tasks http://www.parl.ai/static/docs/tasks.html# 

This collection includes the following datasets or respectivly looks at the following datasets to be included:

* added: http://www.okbqa.org/nlq
* added: http://greententacle.techfak.uni-bielefeld.de/~cunger/qald/
* added: http://linkedspending.org

in production (adding answers):
* https://www.stonetemple.com/great-knowledge-box-showdown/

Overview articles:
* https://github.com/karthikncode/nlp-datasets
* http://www.cs.cmu.edu/~ark/QA-data/
* http://searchivarius.org/dir/000/00I/000
* https://github.com/sebastianruder/NLP-progress/blob/master/question_answering.md

QA datasets to analyze: 
* WebQuestions Semantic Parses Dataset https://www.microsoft.com/en-us/download/confirmation.aspx?id=52763
* GeoQuery, Free917, WebQuestions, SimpleQuestions, GraphQuestions, and QALD
* http://parl.ai/
* www.msmarco.org
* https://github.com/ysu1989/GraphQuestions/tree/master/freebase13
* http://dl.acm.org/citation.cfm?id=2878551
* https://sharc-data.github.io/
* TriviaQA for 95k reading comprehension questions http://nlp.cs.washington.edu/triviaqa/ 
* convai.io 
* https://github.com/deepmind/aqua Algebraic QA
* https://www.microsoft.com/en-us/download/details.aspx?id=52763
* http://datasets.maluuba.com/NewsQA
* https://github.com/ysu1989/GraphQuestions GraphQuestions: compositional questions; multiple paraphrases for each question 
* http://qallme.fbk.eu/index.php?location=benchmark
* http://agarciaduran.org/ 30M questions to freebase
* https://github.com/brmson/yodaqa/wiki/Benchmarks
 * https://github.com/brmson/dataset-factoid-curated for evolution 
 * https://github.com/brmson/dataset-factoid-movies for domain-specific
 * https://github.com/brmson/dataset-factoid-webquestions for a suit
* GeoQuery, Free917, WebQuestions, SimpleQuestions, GraphQuestions, and QALD
* https://github.com/ysu1989/GraphQuestions GraphQuestions: compositional and paraphrased questions 
* http://www-nlp.stanford.edu/software/sempre/
* http://research.microsoft.com/en-us/um/redmond/projects/mctest/ 
* https://sites.google.com/site/trecliveqa2015/
* http://trec.nist.gov/data/qa.html
* http://trec.nist.gov/data/qamain.html
* http://trec.nist.gov/data/qa/add_qaresources.html
* http://www.slideshare.net/andrenfreitas/schema-agnostic
* http://research.microsoft.com/en-us/downloads/88c0021c-328a-4148-a158-a42d7331c6cf/
* http://projects.semwebcentral.org/ (?)
* http://research.signalmedia.co/newsir16/signal-dataset.html
* Kaggle AI challenge or in general multiple choice questions (e.g., QALD entrance exams)
* needs computation: https://github.com/deepmind/rc-data/
* Federated Queries https://code.google.com/archive/p/fbench/
* http://talc1.loria.fr/webnlg/stories/deliverables.html
* http://nlp.stanford.edu/blog/wikitablequestions-a-complex-real-world-question-understanding-dataset/
* https://cs.umd.edu/~miyyer/qblearn/
* https://ciir.cs.umass.edu/downloads/nfL6/
* https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view
* https://machinelearningmastery.com/datasets-natural-language-processing/
* https://arxiv.org/abs/1805.05942
* http://www.aclweb.org/anthology/C18-1178
* http://nlp.uned.es/clef-qa/repository/ave.php
* https://hucvl.github.io/recipeqa/
* https://arxiv.org/pdf/1810.02802.pdf
* https://gluebenchmark.com/
* https://amritasaha1812.github.io/CSQA/_pages/example.html
* https://github.com/conversationai/wikidetox/tree/master/wikiconv
* Interesting study for Google's quality: https://www.emeraldinsight.com/doi/pdfplus/10.1108/LHT-10-2017-0218
* https://github.com/aliannejadi/qulac
* https://link.springer.com/chapter/10.1007/978-3-030-41505-1_21
* https://convex.mpi-inf.mpg.de/ !!!
* https://arxiv.org/abs/2004.10645 very complex QA with a lot of ambiguities
* https://sites.google.com/view/quira/imdb 
* http://tvqa.cs.unc.edu/leaderboard.html
* http://alt.qcri.org/semeval2015/task3/ SemEval-2015 Task 3: Answer Selection in Community Question Answering 
* http://alt.qcri.org/semeval2016/task3/ Semeval-2016 Task 3: Community Question Answering
* https://www.microsoft.com/en-us/download/details.aspx?id=52419 WikiQA (big!)
* https://stanford-qa.com/ 100k+ questions with leaderboard 
* http://www.aclweb.org/anthology/P/P16/P16-1145.pdf WIKIREADING, largest dataset!
* http://www.cl.ecei.tohoku.ac.jp/rite2/doku.php?id=wiki:resources only japanese
* QGSTEC automatic question generation workshop
* http://www.cs.cmu.edu/~ark/QA-data/ 
* http://webscope.sandbox.yahoo.com/catalog.php?datatype=l
* https://arxiv.org/abs/1710.06481
* https://ai.facebook.com/blog/longform-qa/
* https://t.co/CXQ9BfVOyU
* http://qangaroo.cs.ucl.ac.uk/
* https://arxiv.org/abs/1805.03797
* http://jmcauley.ucsd.edu/data/amazon/qa/
* http://www.aclweb.org/aclwiki/index.php?title=Question_Answering_(State_of_the_art) 
* https://stackoverflow.blog/2009/06/stack-overflow-creative-commons-data-dump/
* https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2#.51rfdj1kd 
* http://mrc2018.cipsc.org.cn/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=NLP%20News
*   [Identifying key phrases in text](https://www.crowdflower.com/data-for-everyone/): Question/Answer pairs + context; context was judged if relevant to question/answer. (8 MB)
*   [Jeopardy](http://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/): archive of 216,930 past Jeopardy questions (53 MB)
*   [MCTest](http://research.microsoft.com/en-us/um/redmond/projects/mctest/index.html): a freely available set of 660 stories and associated questions intended for research on the machine comprehension of text; for question answering (1 MB)
*   [Stackoverflow](http://data.stackexchange.com/): 7.3 million stackoverflow questions + other stackexchanges (query tool)
*   [Yahoo! Answers Comprehensive Questions and Answers](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): Yahoo! Answers corpus as of 10/25/2007. Contains 4,483,032 questions and their answers. (3.6 GB)
*   [Yahoo! Answers consisting of questions asked in French](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): Subset of the Yahoo! Answers corpus from 2006 to 2015 consisting of 1.7 million questions posed in French, and their corresponding answers. (3.8 GB)
*   [Yahoo! Answers Manner Questions](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): subset of the Yahoo! Answers corpus from a 10/25/2007 dump, selected for their linguistic properties. Contains 142,627 questions and their answers. (104 MB)
* https://sites.google.com/view/qanta/home
* https://transacl.org/ojs/index.php/tacl/article/view/1325
* https://msropendata.com/datasets/d8d67c14-9d3f-4aeb-8178-4b2f8fb46c55
* https://msropendata.com/datasets/939b1042-6402-4697-9c15-7a28de7e1321
* 758	PhotoshopQuiA: A Corpus of Non-Factoid Questions and Answers for Why-Question Answering / interesting for Wikihow-watodo
* http://www.aclweb.org/anthology/W18-3204
* https://mrqa2018.github.io/
* https://arxiv.org/pdf/1808.07036.pdf
* https://arxiv.org/pdf/1809.00732.pdf
* http://qa.mpi-inf.mpg.de/comqa/
* https://github.com/bdhingra/quasar
* https://hotpotqa.github.io/
* http://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf
* http://aclweb.org/anthology/S18-1009
* temporal QA http://delivery.acm.org/10.1145/3200000/3191536/p1057-jia.pdf
* hotel reviews http://www.europe.naverlabs.com/Blog/ReviewQA-A-novel-relational-aspect-based-opinion-dataset-for-machine-reading
* ComQA https://arxiv.org/abs/1809.09528 http://qa.mpi-inf.mpg.de/comqa/
* https://github.com/kayburns/tom-qa-dataset
* https://arxiv.org/abs/1811.00937
* https://pinafore.github.io/qanta-leaderboard/
* https://www.stateoftheart.ai/
* https://www.aaai.org/Papers/AAAI/2019/AAAI-TafjordO.6869.pdf
* https://github.com/NLP-BigDataLab/QAnalysis-project
* https://www.semanticscholar.org/paper/DROP%3A-A-Reading-Comprehension-Benchmark-Requiring-Dua-Wang/9498f5b9ff0052c22e41979df49bc8efca0a9d17
* https://arxiv.org/pdf/1904.04365.pdf commonsense qa
* https://www.tau-nlp.org/commonsenseqa
* https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Question_Answering_data
* https://towardsdatascience.com/question-answering-for-enterprise-use-cases-70ed39b74296
Bao, J., Duan, N., Yan, Z., Zhou, M., and Zhao, T. (2016). Constraint-based
question answering with knowledge graph. In COLING 2016, 26th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers, December 11-16, 2016, Osaka, Japan, pages 2503–
2514.
* chatbot https://developer.amazon.com/de/blogs/alexa/post/885ec615-314f-425f-a396-5bcffd33dd76/amazon-releases-data-set-of-annotated-conversations-to-aid-development-of-socialbots
Su, Y., Sun, H., Sadler, B., Srivatsa, M., Gur, I., Yan, Z., and Yan, X. (2016). On
generating characteristic-rich question sets for QA evaluation. In Proceedings
of the 2016 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 562–572.
https://sites.google.com/view/quira/musicbrainz
DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs
* https://arxiv.org/abs/1905.08957
* https://arxiv.org/pdf/2004.11861.pdf Event QA
* https://github.com/wenhuchen/HybridQA
* https://scai.info/2020/
* blog posts von Mikhail Galkin 
* https://www.tau-nlp.org/compwebq
* https://foodkg.github.io/kbqa.html
* https://colab.research.google.com/github/huggingface/nlp/blob/master/notebooks/Overview.ipynb#scrollTo=d3RJisGLvSUp source of many datasets and libraries, maybe one could extend this base version in a fork in particular geared towards QA over KGs
* https://arxiv.org/abs/2005.10659 RUBQ contains already a nice overview
* well as muti-hop complex questions, including WebQuestionSP (WQSP), ComplexWebQuestion-1.1 (CWQ), and PathQuestion-Large (PQL),
* https://datasets.quantumstat.com/
* https://github.com/google-research/google-research/tree/master/cfq
* FB5M https://dl.acm.org/doi/pdf/10.1145/3390557.3394296
* https://github.com/microsoft/MIMICS/
* https://arxiv.org/abs/1912.09713
* https://github.com/Yiming-Tan230/MLPQ multi graph qa
* https://zenodo.org/record/3746635 modifiers on QALD
* https://arxiv.org/pdf/1907.09361.pdf -> compare dataset list
* https://arxiv.org/abs/2007.03875 KQA Pro large scale wikidata
* https://twitter.com/ShayneRedford/status/1289250148497776640?s=09 multilingual open domain dataset for reference
* https://arxiv.org/abs/2007.15207 MKQA
* https://medium.com/semantic-tech-hotspot/acl-2020-overview-and-new-benchmarks-81b7fb0e609e
* https://aaai.org/ojs/index.php/AAAI/article/view/4991
* https://arxiv.org/pdf/1607.06275.pdf
* https://t.co/xMUeh2lNHT?amp=1
* https://arxiv.org/abs/2011.01060
* https://allenai.org/data/break
* https://github.com/UKPLab/coling2018-graph-neural-networks-question-answering/
* https://github.com/castorini/SimpleDBpediaQA
* https://www.aclweb.org/anthology/2021.eacl-main.300.pdf
* https://openreview.net/pdf?id=P5UQFFoQ4PJ
* https://arxiv.org/pdf/2107.02865.pdf -> wikidataqa
* http://www.semantic-web-journal.net/content/question-answering-deep-neural-networks-semi-structured-heterogeneous-genealogical-knowledge digital humanities
* https://aclanthology.org/2021.acl-long.357.pdf temporal qa 
* https://aclanthology.org/2021.starsem-1.10.pdf
* https://github.com/apoorvumang/CronKGQA temporal QA
* https://arxiv.org/abs/2108.03509 Wikidata QA

## Focus
This collection aims at becoming a central focus point of question answering research. Using deeper analysis (sentiment, clustering, topic) of a questions will help to understand arising difficulties within QA systems. Moreover, this collection will help also semantic search, e.g. keyword search, phrase search, in later stages.

## Maven Dependency
This library is available as snapshot here: http://maven.aksw.org/archiva/#artifact~snapshots/org.aksw.qa/datasets

```
<dependency>
  <groupId>org.aksw.qa</groupId>
  <artifactId>datasets</artifactId>
  <version>0.5.12</version>
</dependency>
```
Add the following repository:
```
<repository>
			<id>maven.aksw.internal</id>
			<name>University Leipzig, AKSW Maven2 Repository</name>
			<url>http://maven.aksw.org/archiva/repository/internal</url>
		</repository>
		<repository>
			<id>maven.aksw.snapshots</id>
			<name>University Leipzig, AKSW Maven2 Repository</name>
			<url>http://maven.aksw.org/archiva/repository/snapshots</url>
</repository>
```

Look for more interesting libraries here: http://maven.aksw.org/archiva/#browse/org.aksw.qa 

### Acknowledgement
- Sources: https://raw.githubusercontent.com/niderhoff/nlp-datasets/master/README.md
