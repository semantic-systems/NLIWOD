# Question answering datasets

## Datasets included in NLIWOD

| Dataset                  |                   Paper                          | 
|--------------------------|:------------------------------------------------:|
|DBpedia-Entity v2 INEX       |[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|
|DBpedia-Entity v2 QALD2      |[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|
|DBpedia-Entity v2 SemSearch  |[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|
|DBpedia-Entity v2 TREC Entity|[Link](https://www.researchgate.net/publication/318131631_DBpedia-Entity_v2_A_Test_Collection_for_Entity_Search/link/59dc7f73458515e9ab4c669d/download)|
|LCQUAD                    |[Link](http://jens-lehmann.org/files/2017/iswc_lcquad.pdf)|
|NLQ          	           |[Link](http://2015.okbqa.org/nlq)|
|QALD-1                    |[Link](http://qald.aksw.org/1/documents/qald-1-challenge.pdf)|
|QALD-2                    |[Link](http://qald.aksw.org/2/documents/qald-2-challenge.pdf)|
|QALD-3                    |[Link](https://www.researchgate.net/publication/278716415_Multilingual_Question_Answering_over_Linked_Data_QALD-3_Lab_Overview)|
|QALD-4                    |[Link](https://www.researchgate.net/publication/278798193_Question_answering_over_linked_data_QALD-4)|
|QALD-5                    |[Link](https://www.researchgate.net/publication/282124138_Question_Answering_over_Linked_Data_QALD-5)|
|QALD-6                    |[Link](https://link.springer.com/chapter/10.1007/978-3-319-46565-4_13)|
|QALD-7                    |[Link](https://svn.aksw.org/papers/2017/ESWC_2017_QALD/public.pdf)|
|QALD-8                    |[Link](https://www.semanticscholar.org/paper/8th-Challenge-on-Question-Answering-over-Linked-Usbeck-Ngomo/44ddbf4032e70c4aabfa6799df5ee2b5ce51a468)|
|QALD-9                    |[Link](https://www.semanticscholar.org/paper/9th-Challenge-on-Question-Answering-over-Linked-Usbeck-Gusmita/4f83e1b64f57ae0d546076279426e85c0e60298b)|
|SimpleQuestionsWikidata   |[Link](https://www.researchgate.net/publication/319482301_Question_Answering_Benchmarks_for_Wikidata)|
|WDAquaCore0Wikidata       |[Link](https://github.com/WDAqua/WDAquaCore0Questions)|

NOTE: PARL.AI does a tremendous job in including different tasks. Thus it would make sense to analyze their state before starting to include more tasks http://www.parl.ai/static/docs/tasks.html# 

This collection includes the following datasets or respectivly looks at the following datasets to be included:

* added: http://www.okbqa.org/nlq
* added: http://greententacle.techfak.uni-bielefeld.de/~cunger/qald/
* added: http://linkedspending.org

in production (adding answers):
* https://www.stonetemple.com/great-knowledge-box-showdown/

Overview articles:
* https://github.com/karthikncode/nlp-datasets
* http://www.cs.cmu.edu/~ark/QA-data/
* http://searchivarius.org/dir/000/00I/000
* https://github.com/sebastianruder/NLP-progress/blob/master/question_answering.md

QA datasets to analyze: 
* WebQuestions Semantic Parses Dataset https://www.microsoft.com/en-us/download/confirmation.aspx?id=52763
* GeoQuery, Free917, WebQuestions, SimpleQuestions, GraphQuestions, and QALD
* http://parl.ai/
* www.msmarco.org
* https://github.com/ysu1989/GraphQuestions/tree/master/freebase13
* http://dl.acm.org/citation.cfm?id=2878551
* https://sharc-data.github.io/
* TriviaQA for 95k reading comprehension questions http://nlp.cs.washington.edu/triviaqa/ 
* convai.io 
* https://github.com/deepmind/aqua Algebraic QA
* https://www.microsoft.com/en-us/download/details.aspx?id=52763
* http://datasets.maluuba.com/NewsQA
* https://github.com/ysu1989/GraphQuestions GraphQuestions: compositional questions; multiple paraphrases for each question 
* http://qallme.fbk.eu/index.php?location=benchmark
* http://agarciaduran.org/ 30M questions to freebase
* https://github.com/brmson/yodaqa/wiki/Benchmarks
 * https://github.com/brmson/dataset-factoid-curated for evolution 
 * https://github.com/brmson/dataset-factoid-movies for domain-specific
 * https://github.com/brmson/dataset-factoid-webquestions for a suit
* GeoQuery, Free917, WebQuestions, SimpleQuestions, GraphQuestions, and QALD
* https://github.com/ysu1989/GraphQuestions GraphQuestions: compositional and paraphrased questions 
* http://www-nlp.stanford.edu/software/sempre/
* http://research.microsoft.com/en-us/um/redmond/projects/mctest/ 
* https://sites.google.com/site/trecliveqa2015/
* http://trec.nist.gov/data/qa.html
* http://trec.nist.gov/data/qamain.html
* http://trec.nist.gov/data/qa/add_qaresources.html
* http://www.slideshare.net/andrenfreitas/schema-agnostic
* http://research.microsoft.com/en-us/downloads/88c0021c-328a-4148-a158-a42d7331c6cf/
* http://projects.semwebcentral.org/ (?)
* http://research.signalmedia.co/newsir16/signal-dataset.html
* Kaggle AI challenge or in general multiple choice questions (e.g., QALD entrance exams)
* needs computation: https://github.com/deepmind/rc-data/
* Federated Queries https://code.google.com/archive/p/fbench/
* http://talc1.loria.fr/webnlg/stories/deliverables.html
* http://nlp.stanford.edu/blog/wikitablequestions-a-complex-real-world-question-understanding-dataset/
* https://cs.umd.edu/~miyyer/qblearn/
* https://ciir.cs.umass.edu/downloads/nfL6/
* https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view
* https://machinelearningmastery.com/datasets-natural-language-processing/
* https://arxiv.org/abs/1805.05942
* http://www.aclweb.org/anthology/C18-1178
* http://nlp.uned.es/clef-qa/repository/ave.php
* https://hucvl.github.io/recipeqa/
* https://arxiv.org/pdf/1810.02802.pdf
* https://gluebenchmark.com/
* https://amritasaha1812.github.io/CSQA/_pages/example.html
* https://github.com/conversationai/wikidetox/tree/master/wikiconv
* Interesting study for Google's quality: https://www.emeraldinsight.com/doi/pdfplus/10.1108/LHT-10-2017-0218
* https://github.com/aliannejadi/qulac
* https://link.springer.com/chapter/10.1007/978-3-030-41505-1_21
* https://convex.mpi-inf.mpg.de/ !!!
* https://arxiv.org/abs/2004.10645 very complex QA with a lot of ambiguities

out of scope (?) :
* http://tvqa.cs.unc.edu/leaderboard.html
* http://alt.qcri.org/semeval2015/task3/ SemEval-2015 Task 3: Answer Selection in Community Question Answering 
* http://alt.qcri.org/semeval2016/task3/ Semeval-2016 Task 3: Community Question Answering
* https://www.microsoft.com/en-us/download/details.aspx?id=52419 WikiQA (big!)
* https://stanford-qa.com/ 100k+ questions with leaderboard 
* http://www.aclweb.org/anthology/P/P16/P16-1145.pdf WIKIREADING, largest dataset!
* http://www.cl.ecei.tohoku.ac.jp/rite2/doku.php?id=wiki:resources only japanese
* QGSTEC automatic question generation workshop
* http://www.cs.cmu.edu/~ark/QA-data/ 
* http://webscope.sandbox.yahoo.com/catalog.php?datatype=l
* https://arxiv.org/abs/1710.06481
* https://ai.facebook.com/blog/longform-qa/
* https://t.co/CXQ9BfVOyU
* http://qangaroo.cs.ucl.ac.uk/
* https://arxiv.org/abs/1805.03797
* http://jmcauley.ucsd.edu/data/amazon/qa/
* http://www.aclweb.org/aclwiki/index.php?title=Question_Answering_(State_of_the_art) 
* https://stackoverflow.blog/2009/06/stack-overflow-creative-commons-data-dump/
* https://medium.com/startup-grind/fueling-the-ai-gold-rush-7ae438505bc2#.51rfdj1kd 
* http://mrc2018.cipsc.org.cn/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=NLP%20News
*   [Identifying key phrases in text](https://www.crowdflower.com/data-for-everyone/): Question/Answer pairs + context; context was judged if relevant to question/answer. (8 MB)
*   [Jeopardy](http://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/): archive of 216,930 past Jeopardy questions (53 MB)
*   [MCTest](http://research.microsoft.com/en-us/um/redmond/projects/mctest/index.html): a freely available set of 660 stories and associated questions intended for research on the machine comprehension of text; for question answering (1 MB)
*   [Stackoverflow](http://data.stackexchange.com/): 7.3 million stackoverflow questions + other stackexchanges (query tool)
*   [Yahoo! Answers Comprehensive Questions and Answers](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): Yahoo! Answers corpus as of 10/25/2007. Contains 4,483,032 questions and their answers. (3.6 GB)
*   [Yahoo! Answers consisting of questions asked in French](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): Subset of the Yahoo! Answers corpus from 2006 to 2015 consisting of 1.7 million questions posed in French, and their corresponding answers. (3.8 GB)
*   [Yahoo! Answers Manner Questions](http://webscope.sandbox.yahoo.com/catalog.php?datatype=l): subset of the Yahoo! Answers corpus from a 10/25/2007 dump, selected for their linguistic properties. Contains 142,627 questions and their answers. (104 MB)
* https://sites.google.com/view/qanta/home
* https://transacl.org/ojs/index.php/tacl/article/view/1325
* https://msropendata.com/datasets/d8d67c14-9d3f-4aeb-8178-4b2f8fb46c55
* https://msropendata.com/datasets/939b1042-6402-4697-9c15-7a28de7e1321
* 758	PhotoshopQuiA: A Corpus of Non-Factoid Questions and Answers for Why-Question Answering / interesting for Wikihow-watodo
* http://www.aclweb.org/anthology/W18-3204
* https://mrqa2018.github.io/
* https://arxiv.org/pdf/1808.07036.pdf
* https://arxiv.org/pdf/1809.00732.pdf
* http://qa.mpi-inf.mpg.de/comqa/
* https://github.com/bdhingra/quasar
* https://hotpotqa.github.io/
* http://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf
* http://aclweb.org/anthology/S18-1009
* temporal QA http://delivery.acm.org/10.1145/3200000/3191536/p1057-jia.pdf
* hotel reviews http://www.europe.naverlabs.com/Blog/ReviewQA-A-novel-relational-aspect-based-opinion-dataset-for-machine-reading
* ComQA https://arxiv.org/abs/1809.09528 http://qa.mpi-inf.mpg.de/comqa/
* https://github.com/kayburns/tom-qa-dataset
* https://arxiv.org/abs/1811.00937
* https://pinafore.github.io/qanta-leaderboard/
* https://www.stateoftheart.ai/
* https://www.aaai.org/Papers/AAAI/2019/AAAI-TafjordO.6869.pdf
* https://github.com/NLP-BigDataLab/QAnalysis-project
* https://www.semanticscholar.org/paper/DROP%3A-A-Reading-Comprehension-Benchmark-Requiring-Dua-Wang/9498f5b9ff0052c22e41979df49bc8efca0a9d17
* https://arxiv.org/pdf/1904.04365.pdf commonsense qa
* https://www.tau-nlp.org/commonsenseqa
* https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Question_Answering_data
* https://towardsdatascience.com/question-answering-for-enterprise-use-cases-70ed39b74296
Bao, J., Duan, N., Yan, Z., Zhou, M., and Zhao, T. (2016). Constraint-based
question answering with knowledge graph. In COLING 2016, 26th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers, December 11-16, 2016, Osaka, Japan, pages 2503–
2514.
* chatbot https://developer.amazon.com/de/blogs/alexa/post/885ec615-314f-425f-a396-5bcffd33dd76/amazon-releases-data-set-of-annotated-conversations-to-aid-development-of-socialbots
Su, Y., Sun, H., Sadler, B., Srivatsa, M., Gur, I., Yan, Z., and Yan, X. (2016). On
generating characteristic-rich question sets for QA evaluation. In Proceedings
of the 2016 Conference on Empirical Methods in Natural Language Processing,
EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 562–572.

DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs
* https://arxiv.org/abs/1905.08957
* https://arxiv.org/pdf/2004.11861.pdf Event QA
* https://github.com/wenhuchen/HybridQA
* https://scai.info/2020/
* blog posts von Mikhail Galkin 
* https://www.tau-nlp.org/compwebq
* https://foodkg.github.io/kbqa.html
* https://colab.research.google.com/github/huggingface/nlp/blob/master/notebooks/Overview.ipynb#scrollTo=d3RJisGLvSUp source of many datasets and libraries, maybe one could extend this base version in a fork in particular geared towards QA over KGs
* https://arxiv.org/abs/2005.10659
* well as muti-hop complex questions, including WebQuestionSP (WQSP), ComplexWebQuestion-1.1 (CWQ), and PathQuestion-Large (PQL),
* https://datasets.quantumstat.com/
* https://github.com/google-research/google-research/tree/master/cfq
* FB5M https://dl.acm.org/doi/pdf/10.1145/3390557.3394296

## Focus
This collection aims at becoming a central focus point of question answering research. Using deeper analysis (sentiment, clustering, topic) of a questions will help to understand arising difficulties within QA systems. Moreover, this collection will help also semantic search, e.g. keyword search, phrase search, in later stages.

## Maven Dependency
This library is available as snapshot here: http://maven.aksw.org/archiva/#artifact~snapshots/org.aksw.qa/datasets

```
<dependency>
  <groupId>org.aksw.qa</groupId>
  <artifactId>datasets</artifactId>
  <version>0.5.12</version>
</dependency>
```
Add the following repository:
```
<repository>
			<id>maven.aksw.internal</id>
			<name>University Leipzig, AKSW Maven2 Repository</name>
			<url>http://maven.aksw.org/archiva/repository/internal</url>
		</repository>
		<repository>
			<id>maven.aksw.snapshots</id>
			<name>University Leipzig, AKSW Maven2 Repository</name>
			<url>http://maven.aksw.org/archiva/repository/snapshots</url>
</repository>
```

Look for more interesting libraries here: http://maven.aksw.org/archiva/#browse/org.aksw.qa 

### Acknowledgement
- Sources: https://raw.githubusercontent.com/niderhoff/nlp-datasets/master/README.md
